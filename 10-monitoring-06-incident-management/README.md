# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).
| First Header  | Second Header |
| ------------- | ------------- |
| **Краткое описание инцидента** | В 22:52 UTC 21 октября 2018 в результате работ на 100G оптическом оборудовании произошли проблемы на сетевых разделах и последующих сбоях в БД. В результата возникла несогласованность данных на сервисах. Произошла деградация сервиса в течении 24 часов и 11 минут. |
| **Предшествующие события**     | Работы по техническому обслуживанию для замены неисправного оптического оборудования 100G привели к потере связи между сетевым центром Западного побережья США и основным центром обработки данных на Восточном побережье США. |
| **Причина инцидента**          | Выполнялись работы по техническому обслуживанию для замены неисправного оптического оборудования 100G привели к потере связи между сетевым центром Западного побережья США и основным центром обработки данных на Восточном побережье США. Связь между этими местоположениями была восстановлена за 43 секунды, но это короткое отключение вызвало цепочку событий, которые привели к 24-часовому и 11-минутному ухудшению обслуживания. |
| **Воздействие**                | Пострадали несколько внутренних систем, что привело к отображению информации, которая была устаревшей и непоследовательной. В конечном счете, никакие пользовательские данные не были потеряны. На протяжении большей части инцидента GitHub также не мог обслуживать события веб-перехватчика или создавать и публиковать сайты GitHub Pages. |
| **Обнаружение**                | Инженеры команды быстрого реагирования определили, что топологии для многочисленных кластеров баз данных находятся в неожиданном состоянии. |
| **Реакция**                    | Деградация сервиса в течении 24 часов и 11 минут |
| **Восстановление**             | Было выполнено восстановления данных из бекапов и  репликации всех имеющихся данных с хостов с актуальными данными для восстановления 100% целостности данных во всех кластерах хранения данных. |
| **Таймлайн**                   | 2018.10.21 22:52 UTC - потеря консенсуса между серверами в дата-центрах в результате описанного инцидента. После восстановления была попытка восстановления целостности кластера, восстановления консенсуса, но данные в БД различались что привело к несогласованности в рамках кластера
2018.10.21 22:54 UTC - Мониторинг генерировал Алерты, инженеры поддержки реагировали на алерты, в 23:02 обнаружили несоответствие статуса кластера ожидаемому. Выявлено отсутсвие серверов из US East Coast
2018.10.21 23:07 UTC - отключены внутренние инструменны развертывания для предотвращения дополнительных имзменй. Сайт переведен в желтый статус и автомтически зафикисрован инциден в системе управления сбоями
2018.10.21 23:13 UTC - после выявления воздействия на множественные сервера, выведены дополнительные инженеры, выполнены действия для сохранения пользовательских данных, но деградация системы не была остановлена
2018.10.21 23:19 UTC - Были остановлены некоторые процессы (принудительная деградация системы) с целью повышения скорости восстановления
2018.10.22 00:05 UTC - Разработка плана по восстановления системы и синхронизации репликаций данных. Обновлен статус, чтобы сообщить пользователям, что мы собираемся выполнить контролируемую отработку отказа внутренней системы хранения данных.
2018.10.22 00:41 UTC - Запущен процесс бекапирования данных, мониторинг состояния работ
2018.10.22 06:51 UTC - бэкапы выполнены US East Coast data center и запущенно реплицирование с серверов в West Coast.
2018.10.22 07:46 UTC - опубликована расширенная информация для пользователей
2018.10.22 11:12 UTC - Восстановлены сервера в US East Coast, продолжается реплицирование. Наблюдается повышенная нагрузка при реплицировании.
2018.10.22 13:15 UTC - Приближались к пиковому периоду нагрузок. Увеличили количество репликаций для снятии растущей нагрузки по реплицированию.
2018.10.22 16:24 UTC - Реплицирование синхронизировано, переключение в штатную топологию MySQL
2018.10.22 16:45 UTC - После восстановления возникла необходимость балансировки нагрузки для восстановления 100% услуг клиентам. Для восстановления уже имеющихся данных пользователей включили обработку, так же подняли TTL до полного завершения и возвращения к штатной работе.
2018.10.22 23:03 UTC - Работа возвращена к штатному поведению |
| **Последующие действия**       | Были собранны логи по всем MySQL серверам, производится анализ логов для выявления запросов которые требуется обработать в ручную и информировать пользователей о возможных проблемах.
Технические инициативы:
Настройка конфигурации Orchestrator, чтобы предотвратить продвижение праймериз базы данных через региональные границы.
Мы ускорили переход на новый механизм отчетности о состоянии, который предоставит нам более богатый форум для обсуждения активных инцидентов более четким и понятным языком.
За несколько недель до этого инцидента мы начали общекорпоративную инженерную инициативу по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в активном/активном/активном дизайне.
Мы займем более активную позицию при проверке наших предположений. |


---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---


| First Header  | Second Header |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |

